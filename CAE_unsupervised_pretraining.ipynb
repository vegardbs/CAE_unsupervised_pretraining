{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Odzhc_s4b_4J"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Flatten, InputLayer, Conv2D, Conv2DTranspose, MaxPool2D\n",
    "from keras.layers import Dropout, GaussianNoise\n",
    "from keras import Sequential, Model\n",
    "from sklearn.utils import compute_class_weight\n",
    "import os\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tied_convolution\n",
    "from tied_convolution import Conv2DTranspose_tied\n",
    "\n",
    "class CAE_classifier:\n",
    "    \"\"\" \n",
    "    Class to build and train combined autoencoder and classifier networks.\n",
    "\n",
    "    --MAIN METHODS--\n",
    "\n",
    "    build_autoencoder():\n",
    "      Method to build the encoder and autoencoder networks.\n",
    "      The encoder is passed as a layer to the autoencoder and classifier networks,\n",
    "      so to access the layers within the encoder block, use autoencoder.layers[0].layers\n",
    "      > Gets called when an instance of the class is created.\n",
    "\n",
    "    train_autoencoder(x_train,x_test):\n",
    "      Method to train the autoencoder. The input data and target data is the same,\n",
    "      since the goal is to reconstruct the input. Data shape has to be (-1,) + input_shape\n",
    "\n",
    "    build_classifier(pretrained = True):\n",
    "      Method to build a classifer model. \n",
    "      If the pretrained keyword is True, weights from the trained autoencoder gets\n",
    "      copied to the encoder block of the classifier. If it is False, the network\n",
    "      is initialized with the same architecture, but the weights and biases are random.\n",
    "      > Gets called by the train_classifer method.\n",
    "\n",
    "    train_classfier(data,val_data, pretrained = True):\n",
    "      Method to train a classifer model.\n",
    "      If the pretrained keyword is True, a model with pretrained weights from\n",
    "      the autoencoder is created. If it is False, an identical model with randomized\n",
    "      initial weights is crated.\n",
    "\n",
    "    evaluate_classifier(x_test, y_test, key = \"pretrained_classifier\"):\n",
    "      Method to evaluate the classfiers on test data.\n",
    "      Keyword determine which classifier should be evaluated.\n",
    "\n",
    "    --VISUALIZATION METHODS--\n",
    "\n",
    "    plot_reconstruction(image):\n",
    "      Method to plot the autoencoder reconstruction of provided image\n",
    "\n",
    "    plot_filters(key = \"autoencoder):\n",
    "      Plots the filters of the first convolutional layer.\n",
    "      Keyword determine which model the filters come from.\n",
    "\n",
    "    plot_feature_map(key = \"autoencoder):\n",
    "      Method to plot the feature map of the first convolutional layer.\n",
    "      Keyword determines which model the feature map come from.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.pretrained_classifier = None\n",
    "        self.rand_init_classifier = None\n",
    "        \n",
    "        self.autoencoder, self.encoder = self.build_autoencoder()\n",
    "\n",
    "    def build_autoencoder(self):\n",
    "\n",
    "        padding = \"same\"\n",
    "        optimizer = \"adam\"\n",
    "        activation = \"relu\"\n",
    "   \n",
    "        conv1     = Conv2D(128, (5,5), activation = activation,padding=padding, name = \"conv1\")\n",
    "        max_pool1 = MaxPool2D((2,2))\n",
    "        conv2     = Conv2D(64,  (5,5), activation = activation,padding=padding)\n",
    "        max_pool2 = MaxPool2D((2,2))\n",
    "        conv3     = Conv2D(32,  (5,5), activation = activation,padding=padding)\n",
    "\n",
    "        tied_conv1 = Conv2DTranspose_tied(64,  (5,5), padding=padding, activation = activation, tied_to = conv3, strides=(2,2))\n",
    "        tied_conv2 = Conv2DTranspose_tied(128, (5,5), padding=padding, activation = activation, tied_to = conv2, strides=(2,2))\n",
    "        tied_conv3 = Conv2DTranspose_tied(3,   (5,5), padding=padding, activation = activation, tied_to = conv1)\n",
    "\n",
    "        encoder = Sequential([\n",
    "            conv1,\n",
    "            max_pool1,\n",
    "            conv2,\n",
    "            max_pool2,\n",
    "            conv3,\n",
    "        ])\n",
    "\n",
    "        autoencoder = Sequential([\n",
    "            InputLayer(input_shape=(32,32,3)),\n",
    "            GaussianNoise(0.2),\n",
    "            encoder,\n",
    "            tied_conv1,\n",
    "            tied_conv2,\n",
    "            tied_conv3])\n",
    "        \n",
    "        autoencoder.compile(optimizer = optimizer, loss=\"mse\")\n",
    "        return autoencoder, encoder\n",
    "    \n",
    "    def train_autoencoder(self, x_train, x_test, epochs, batch_size, verbose = 1):\n",
    "        \n",
    "        train_datagen = ImageDataGenerator(\n",
    "          samplewise_center=True,\n",
    "          samplewise_std_normalization=True)\n",
    "        \n",
    "        test_datagen = ImageDataGenerator(\n",
    "          samplewise_center=True,\n",
    "          samplewise_std_normalization=True)\n",
    "        \n",
    "        train_datagen.fit(x_train)\n",
    "        test_datagen.fit(x_test)\n",
    "\n",
    "        train_iterator = train_datagen.flow(x_train, x_train, batch_size=batch_size)\n",
    "        test_iterator  = test_datagen.flow(x_test, x_test, batch_size=batch_size)\n",
    "\n",
    "        history = self.autoencoder.fit_generator(train_iterator,\n",
    "                            epochs = epochs,\n",
    "                            steps_per_epoch = len(x_train) // batch_size,\n",
    "                            validation_data = test_iterator,\n",
    "                            validation_steps = len(x_test) // batch_size,\n",
    "                            verbose = verbose)\n",
    "\n",
    "        return history\n",
    "    \n",
    "        \n",
    "    def build_classifier(self, pretrained = True):\n",
    "\n",
    "        optimizer = \"adam\"\n",
    "        encoder_copy = keras.models.clone_model(self.encoder)\n",
    "        \n",
    "        if pretrained:\n",
    "            encoder_copy.set_weights(self.encoder.get_weights())\n",
    "\n",
    "        classifier = Sequential([\n",
    "               InputLayer(input_shape = self.input_shape),\n",
    "               GaussianNoise(0.2),\n",
    "               encoder_copy,\n",
    "               Flatten(),\n",
    "               Dropout(0.2),\n",
    "               Dense(256, activation = \"relu\"),\n",
    "               Dropout(0.2),\n",
    "               Dense(10, activation = \"softmax\")\n",
    "               ])\n",
    "        \n",
    "        classifier.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "        return classifier\n",
    "    \n",
    "        \n",
    "    def train_classifier(self, data, val_data, epochs, batch_size, pretrained = True, class_weight = None, data_augmentation = False, verbose = 1):\n",
    "        if pretrained:\n",
    "            self.pretrained_classifier = self.build_classifier(pretrained)\n",
    "            model = self.pretrained_classifier\n",
    "        else:    \n",
    "            self.rand_init_classifier = self.build_classifier(pretrained)\n",
    "            model = self.rand_init_classifier\n",
    "        \n",
    "        x_train, y_train = data\n",
    "        x_val,  y_val  = val_data\n",
    "\n",
    "        y_train_ohe = self.one_hot_encode(y_train)\n",
    "        y_val_ohe  = self.one_hot_encode(y_val)\n",
    "\n",
    "        if class_weight:\n",
    "            weights = compute_class_weight(\"balanced\",np.unique(y_train),y_train.reshape(-1,))\n",
    "            class_weight = {class_ind:weight for class_ind, weight in enumerate(weights)}\n",
    "\n",
    "        if data_augmentation:\n",
    "            train_datagen = ImageDataGenerator(\n",
    "            samplewise_center=True,\n",
    "            samplewise_std_normalization=True,\n",
    "            rotation_range = 15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "        else:\n",
    "            train_datagen = ImageDataGenerator(\n",
    "            samplewise_center=True,\n",
    "            samplewise_std_normalization=True)\n",
    "          \n",
    "        val_datagen = ImageDataGenerator(\n",
    "            samplewise_center=True,\n",
    "            samplewise_std_normalization=True)\n",
    "      \n",
    "        train_datagen.fit(x_train)\n",
    "        val_datagen.fit(x_val)\n",
    "            \n",
    "        train_iterator = train_datagen.flow(x_train, y_train_ohe, batch_size=batch_size)\n",
    "        val_iterator = val_datagen.flow(x_val, y_val_ohe, batch_size=batch_size)\n",
    "\n",
    "        history = model.fit_generator(train_iterator,\n",
    "                            epochs = epochs,\n",
    "                            steps_per_epoch = len(x_train) // batch_size,\n",
    "                            validation_data = val_iterator,\n",
    "                            validation_steps = len(x_val) // batch_size,\n",
    "                            class_weight = class_weight,\n",
    "                            verbose = verbose)\n",
    "        return history\n",
    "\n",
    "\n",
    "    def evaluate_classifier(self, x_test, y_test, key = \"pretrained_classifier\"):\n",
    "        keys = {\"pretrained_classifier\": self.pretrained_classifier,\n",
    "                \"rand_init_classifier\": self.rand_init_classifier}\n",
    "\n",
    "        model = keys[key]\n",
    "        \n",
    "        test_datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True)\n",
    "\n",
    "        test_datagen.fit(x_test)\n",
    "        y_test_ohe = self.one_hot_encode(y_test)\n",
    "\n",
    "        test_iterator = test_datagen.flow(x_test, y_test_ohe, batch_size=64)\n",
    "\n",
    "        evaluation = model.evaluate(test_iterator)\n",
    "        print(\"Accuracy of \" + key + f\" on test data is {100*evaluation[1]:.2f}%\")\n",
    "        return evaluation\n",
    "\n",
    "\n",
    "    \"\"\" ----- Vizualisation methods and helper functions ----- \"\"\"\n",
    "\n",
    "\n",
    "    def one_hot_encode(self, y_labels):\n",
    "        y_labels_ohe = [np.eye(10,1,k=-int(label[0])) for label in y_labels]\n",
    "        y_labels_ohe = np.array(y_labels_ohe).reshape(-1,10)\n",
    "        return y_labels_ohe\n",
    "\n",
    "    # For this to method to work as intended, the sample-wise standardization has to be turned off\n",
    "    def plot_reconstruction(self, images):\n",
    "        fig = plt.figure(figsize = (10,5))\n",
    "        n_imgs = len(images)\n",
    "\n",
    "        for n in range(1,6):\n",
    "            img = images[n].reshape(self.input_shape)\n",
    "            ae_img = self.autoencoder.predict(img.reshape((1,)+self.input_shape))\n",
    "\n",
    "            plt.subplot(2,5,n)\n",
    "            plt.imshow(img)\n",
    "            frame = plt.gca()\n",
    "            frame.axes.xaxis.set_visible(False)\n",
    "            frame.axes.yaxis.set_visible(False)\n",
    "\n",
    "            plt.subplot(2,5,n+5)\n",
    "            plt.imshow(ae_img.reshape(self.input_shape))\n",
    "            frame = plt.gca()\n",
    "            frame.axes.xaxis.set_visible(False)\n",
    "            frame.axes.yaxis.set_visible(False)\n",
    "    \n",
    "        \n",
    "    def plot_filters(self, key=\"autoencoder\"):\n",
    "        keys = {\"autoencoder\":self.autoencoder,\n",
    "                \"pretrained_classifier\":self.pretrained_classifier,\n",
    "                \"rand_init_classifier\":self.rand_init_classifier}\n",
    "        \n",
    "        model = keys[key]\n",
    "        filters = model.get_weights()[0]\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        \n",
    "        for n in range(min(filters.shape[-1],100)):\n",
    "            filt = filters[...,n]\n",
    "            f_min,f_max = filt.min(), filt.max() \n",
    "            filt = (filt-f_min)/(f_max-f_min)\n",
    "            plt.subplot(10,10,n+1)\n",
    "            plt.imshow(filt)\n",
    "            frame = plt.gca()\n",
    "            frame.axes.xaxis.set_visible(False)\n",
    "            frame.axes.yaxis.set_visible(False)\n",
    "            \n",
    "    def plot_feature_map(self, image, key = \"autoencoder\"):\n",
    "        keys = {\"autoencoder\": self.autoencoder,\n",
    "                \"pretrained_classifier\": self.pretrained_classifier,\n",
    "                \"rand_init_classifier\": self.rand_init_classifier}\n",
    "        \n",
    "        model = keys[key].layers[1]\n",
    "        feature_map_model = Model(inputs=model.inputs, outputs=model.get_layer(\"conv1\").output)\n",
    "        feature_map = feature_map_model.predict(image.reshape(1,32,32,3))\n",
    "\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "        for n in range(min(feature_map.shape[-1],100)):\n",
    "            plt.subplot(10,10,n+1)\n",
    "            features = feature_map[0,...,n]\n",
    "\n",
    "            f_min,f_max = features.min(), features.max() \n",
    "            features = (features-f_min)/(f_max-f_min)\n",
    "\n",
    "            plt.imshow(features,cmap =\"gray\")\n",
    "            frame = plt.gca()\n",
    "            frame.axes.xaxis.set_visible(False)\n",
    "            frame.axes.yaxis.set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1x4h5ymxPfL"
   },
   "outputs": [],
   "source": [
    "\"\"\"------------------Data processing functions------------------\"\"\"\n",
    "\n",
    "def remove_samples(x_data, y_labels, num_samples, categories = (2,4,9)):\n",
    "    \"\"\" \n",
    "    Function to remove a set amount of samples of the given categories.\n",
    "    Returns a new downsampled dataset.\n",
    "    \"\"\"\n",
    "    assert ((y_labels.shape[1] == 1) or (len(y_labels.shape) == 1)) , \"Label shape unrecognized\"\n",
    "    assert (len(x_data) == len(y_labels)), \"Number of datasamples does not match number of labels\"\n",
    "\n",
    "    to_remove = []\n",
    "    for category in categories:\n",
    "        category_inds = np.where(y_labels == category)[0][:num_samples]\n",
    "        to_remove.append(category_inds)\n",
    "\n",
    "    to_remove = np.hstack(to_remove)\n",
    "\n",
    "    x_data = np.delete(x_data, to_remove, axis = 0)\n",
    "    y_labels = np.delete(y_labels, to_remove, axis = 0)\n",
    "\n",
    "    return x_data, y_labels\n",
    "\n",
    "\n",
    "def horizontal_flip(x_data, y_labels, categories = (2,4,9)):\n",
    "    \"\"\" \n",
    "    Function to create horizontal copies of all the images of a given category.\n",
    "    Returns a new dataset upsampled with flipped copies.\n",
    "    \"\"\"\n",
    "    new_imgs = []\n",
    "    new_labels = []\n",
    "    for category in categories:\n",
    "        category_inds = np.where(y_labels == category)[0]\n",
    "        to_flip = x_data[category_inds]\n",
    "        for img in to_flip:\n",
    "            flipped = np.fliplr(img)\n",
    "            new_imgs.append(flipped)\n",
    "            new_labels.append(category)\n",
    "            \n",
    "    new_imgs = np.array(new_imgs)\n",
    "    new_labels = np.array(new_labels).reshape((-1,1))\n",
    "\n",
    "    data   = np.vstack([x_data,   new_imgs])\n",
    "    labels = np.vstack([y_labels, new_labels])\n",
    "\n",
    "    idx = np.random.permutation(data.shape[0])\n",
    "\n",
    "    return data[idx], labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJ38sjtArX50"
   },
   "source": [
    "# Example usage of the majority downsampling method\n",
    "To use this class for the other methods, the following changes has to be made:\n",
    "\n",
    "1. Minority upsampling: use min_categories when calling remove_samples on the training data, and uncomment the line where horizontal flip is called. Also remember to set horizontal_flip = False for the data augmentation in the train_classifier class method\n",
    "\n",
    "2. Class weights: use min_categories when calling remove_samples on the training data, and set class_weight = True when training the classifiers\n",
    "\n",
    "In the following code block we import the cifar-10 dataset, remove half the samples of all categories, and split the training set into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kDucCoGgdcm2",
    "outputId": "dd890fd0-d927-4399-93df-ce50f08fdcbd"
   },
   "outputs": [],
   "source": [
    "\"\"\" Importing data and separating it into train, test and validation \"\"\"\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "min_categories = (2,4,9)\n",
    "all_categories = np.arange(10)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "x_train, y_train = remove_samples(x_train, y_train, 2500, categories = all_categories)\n",
    "x_test,  y_test  = remove_samples(x_test,  y_test,  500 , categories = all_categories)\n",
    "\n",
    "# Uncomment next line to create horizontally flipped copies\n",
    "#x_train, y_train = horizontal_flip(x_train,y_train, categories= min_categories) \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, shuffle = True, test_size = 0.05)\n",
    "\n",
    "\n",
    "print(f\"Shape of x-train is {x_train.shape} and y-train is {y_train.shape} \")\n",
    "print(f\"Shape of x-val is {x_val.shape} and y-val is {y_val.shape} \")\n",
    "print(f\"Shape of x-test is {x_test.shape} and y-test is {y_test.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfN-ACNr2Rf"
   },
   "source": [
    "We then create an instance of the convolutional autoencoder pretraining class, and print the summary of the encoder and autoencoder network. Since we employ tied weights on the transpose convolutions, the number of parameters shown for those layers are only the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "A8iJczOZdliq",
    "outputId": "be7d54a8-e63e-4713-a19b-37ccc49ef406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 32, 32, 128)       9728      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          51232     \n",
      "=================================================================\n",
      "Total params: 265,824\n",
      "Trainable params: 265,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 8, 8, 32)          265824    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_tied_1 (Con (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_tied_2 (Con (None, 32, 32, 128)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_tied_3 (Con (None, 32, 32, 3)         3         \n",
      "=================================================================\n",
      "Total params: 266,019\n",
      "Trainable params: 266,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32,32,3)\n",
    "model = CAE_classifier(input_shape)\n",
    "model.encoder.summary()\n",
    "model.autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9kqwIdXXsGrF"
   },
   "source": [
    "Next we train the autoencoder using a batch size of 64 for 20 epochs. Both the training and testing images are sample-wise standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "n1233RdWjcox",
    "outputId": "1ad7afa8-fafb-4a60-841d-d892cfeaaada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "371/371 [==============================] - 10s 28ms/step - loss: 0.0323 - val_loss: 0.0185\n",
      "Epoch 2/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0166 - val_loss: 0.0141\n",
      "Epoch 3/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 4/20\n",
      "371/371 [==============================] - 9s 23ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 5/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 6/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 7/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 8/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 9/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 10/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 11/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 12/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 13/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 14/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 15/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 16/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 17/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 18/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 19/20\n",
      "371/371 [==============================] - 8s 23ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 20/20\n",
      "371/371 [==============================] - 8s 22ms/step - loss: 0.0081 - val_loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbca6d07f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_autoencoder(x_train, x_test, epochs = 20, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqbKKIlzsTFa"
   },
   "source": [
    "Here we plot the 100 first filters obtained from the first convolutional layer of the autoencoder, i.e. the filters applied to the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "N7yVZrgCmLSe",
    "outputId": "7403fc16-426f-48aa-a482-bef05f7ae291"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAIxCAYAAABNZLJ5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyGc2SlO2FJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 100 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_filters(\"autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Jaks7OYsgLw"
   },
   "source": [
    "Next we train a classifier using the pretrained weights from the autoencoder. The batch size is 128 and we train for 20 epochs with data augmentation (horizontal flip, 15% angle rotation and 10% vertical and horizontal shifts). We then evaluate the converged model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "-hNJxN4P46Ng",
    "outputId": "ae0176e4-9bba-4f93-b9c7-ab731701181b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 1.7095 - acc: 0.3778 - val_loss: 1.4426 - val_acc: 0.4679\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 18s 95ms/step - loss: 1.4371 - acc: 0.4839 - val_loss: 1.2928 - val_acc: 0.5374\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 18s 100ms/step - loss: 1.2825 - acc: 0.5403 - val_loss: 1.1313 - val_acc: 0.6087\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 18s 98ms/step - loss: 1.1738 - acc: 0.5840 - val_loss: 1.1159 - val_acc: 0.6034\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 18s 99ms/step - loss: 1.1052 - acc: 0.6071 - val_loss: 0.9563 - val_acc: 0.6480\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 18s 100ms/step - loss: 1.0418 - acc: 0.6339 - val_loss: 0.9523 - val_acc: 0.6595\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 18s 99ms/step - loss: 1.0023 - acc: 0.6500 - val_loss: 1.0164 - val_acc: 0.6346\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 18s 96ms/step - loss: 0.9595 - acc: 0.6657 - val_loss: 0.9012 - val_acc: 0.6783\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 18s 98ms/step - loss: 0.9184 - acc: 0.6778 - val_loss: 0.9000 - val_acc: 0.6925\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 18s 97ms/step - loss: 0.8824 - acc: 0.6901 - val_loss: 0.9491 - val_acc: 0.6872\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 18s 95ms/step - loss: 0.8623 - acc: 0.6961 - val_loss: 0.8564 - val_acc: 0.6892\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 18s 96ms/step - loss: 0.8426 - acc: 0.7065 - val_loss: 0.8721 - val_acc: 0.7041\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 18s 99ms/step - loss: 0.8054 - acc: 0.7142 - val_loss: 0.8821 - val_acc: 0.7094\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 18s 96ms/step - loss: 0.7989 - acc: 0.7182 - val_loss: 0.8646 - val_acc: 0.7059\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 18s 98ms/step - loss: 0.7756 - acc: 0.7254 - val_loss: 0.8707 - val_acc: 0.7050\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 18s 96ms/step - loss: 0.7703 - acc: 0.7313 - val_loss: 0.8039 - val_acc: 0.7299\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 18s 98ms/step - loss: 0.7352 - acc: 0.7414 - val_loss: 0.8647 - val_acc: 0.7139\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 18s 97ms/step - loss: 0.7175 - acc: 0.7480 - val_loss: 0.8580 - val_acc: 0.7184\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 0.7146 - acc: 0.7501 - val_loss: 0.8311 - val_acc: 0.7228\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 18s 95ms/step - loss: 0.7034 - acc: 0.7586 - val_loss: 0.8101 - val_acc: 0.7255\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of pretrained_classifier on test data is 72.50%\n"
     ]
    }
   ],
   "source": [
    "history = model.train_classifier((x_train,y_train),(x_val,y_val), pretrained = True, batch_size = 128, epochs = 20, class_weight=None, data_augmentation=True)\n",
    "test_results = model.evaluate_classifier(x_test,y_test,key=\"pretrained_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UATRNcNPszD7"
   },
   "source": [
    "Here we perform the same training as above, but this time we create a new classifier network without copying the weights from the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "15IbMUay5Z8j",
    "outputId": "c4c0964b-6ed3-42fe-90e8-63dad66b28ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 1.7090 - acc: 0.3773 - val_loss: 1.4643 - val_acc: 0.4479\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 1.4152 - acc: 0.4925 - val_loss: 1.3268 - val_acc: 0.5392\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 17s 94ms/step - loss: 1.2814 - acc: 0.5437 - val_loss: 1.1738 - val_acc: 0.5731\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 1.1873 - acc: 0.5810 - val_loss: 1.1325 - val_acc: 0.6025\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 1.1154 - acc: 0.6083 - val_loss: 0.9724 - val_acc: 0.6640\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 17s 93ms/step - loss: 1.0497 - acc: 0.6294 - val_loss: 0.9846 - val_acc: 0.6381\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 1.0117 - acc: 0.6433 - val_loss: 0.9324 - val_acc: 0.6613\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.9605 - acc: 0.6631 - val_loss: 0.8982 - val_acc: 0.6667\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.9169 - acc: 0.6796 - val_loss: 0.8562 - val_acc: 0.6898\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.8980 - acc: 0.6850 - val_loss: 0.9126 - val_acc: 0.6863\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.8855 - acc: 0.6884 - val_loss: 0.8932 - val_acc: 0.6910\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 17s 93ms/step - loss: 0.8509 - acc: 0.7012 - val_loss: 0.8601 - val_acc: 0.6881\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 0.8238 - acc: 0.7093 - val_loss: 0.9014 - val_acc: 0.6845\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.8068 - acc: 0.7136 - val_loss: 0.8186 - val_acc: 0.7112\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 17s 89ms/step - loss: 0.7876 - acc: 0.7264 - val_loss: 0.8856 - val_acc: 0.6854\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 0.7771 - acc: 0.7286 - val_loss: 0.8999 - val_acc: 0.6836\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 17s 92ms/step - loss: 0.7480 - acc: 0.7367 - val_loss: 0.8423 - val_acc: 0.7059\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.7327 - acc: 0.7385 - val_loss: 0.9131 - val_acc: 0.6881\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.7283 - acc: 0.7445 - val_loss: 0.8458 - val_acc: 0.7148\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.7098 - acc: 0.7507 - val_loss: 0.8486 - val_acc: 0.7157\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of rand_init_classifier on test data is 72.34%\n"
     ]
    }
   ],
   "source": [
    "history = model.train_classifier((x_train,y_train),(x_val,y_val), pretrained = False, batch_size = 128, epochs = 20, class_weight=None, data_augmentation=True)\n",
    "test_results = model.evaluate_classifier(x_test,y_test, key = \"rand_init_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITeHVzbPtIay"
   },
   "source": [
    "Finally, in the following code block we repeat the experiment 10 times and store the model weights as well as the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWcrOHoEyo-0"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"model_weights/pretrained_classifier\")\n",
    "os.makedirs(\"model_weights/rand_init_classifier\")\n",
    "os.makedirs(\"model_weights/autencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "nOt7KQ9KzE_V",
    "outputId": "3a662347-d5e5-4199-e551-76f5f81045fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1/10\n",
      "79/79 [==============================] - 1s 12ms/step\n",
      "Accuracy of pretrained_classifier on test data is 74.12%\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of rand_init_classifier on test data is 73.70%\n",
      "Experiment 2/10\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of pretrained_classifier on test data is 72.58%\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of rand_init_classifier on test data is 74.12%\n",
      "Experiment 3/10\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of pretrained_classifier on test data is 73.46%\n",
      "79/79 [==============================] - 1s 12ms/step\n",
      "Accuracy of rand_init_classifier on test data is 70.56%\n",
      "Experiment 4/10\n",
      "79/79 [==============================] - 1s 11ms/step\n",
      "Accuracy of pretrained_classifier on test data is 72.54%\n"
     ]
    }
   ],
   "source": [
    "histories = {\"autoencoder\":[],\n",
    "             \"pretrained_classifier\":[],\n",
    "             \"rand_init_classifier\":[]}\n",
    "\n",
    "results = {\"pretrained_classifier\":[],\n",
    "             \"rand_init_classifier\":[]}\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "for n in range(10):\n",
    "    print(f\"Experiment {n+1}/{10}\")\n",
    "    model = CAE_classifier(input_shape)\n",
    "\n",
    "    history = model.train_autoencoder(x_train,x_val, epochs = epochs, batch_size = 65, verbose = 0)\n",
    "    model.autoencoder.save_weights(\"model_weights/autencoder/weights_\" + str(n))\n",
    "    histories[\"autoencoder\"].append(history)\n",
    "\n",
    "    history = model.train_classifier((x_train,y_train),(x_val,y_val), pretrained = True, data_augmentation=True,batch_size = batch_size, epochs = epochs, verbose = 0)\n",
    "    model.pretrained_classifier.save_weights(\"model_weights/pretrained_classifier/weights_\" + str(n))\n",
    "    result = model.evaluate_classifier(x_test,y_test, key = \"pretrained_classifier\")\n",
    "    histories[\"pretrained_classifier\"].append(history)\n",
    "    results[\"pretrained_classifier\"].append(result)\n",
    "\n",
    "    history = model.train_classifier((x_train,y_train),(x_val,y_val), pretrained = False, data_augmentation=True, batch_size = batch_size, epochs = epochs, verbose = 0)\n",
    "    model.rand_init_classifier.save_weights(\"model_weights/rand_init_classifier/weights_\" + str(n))\n",
    "    result = model.evaluate_classifier(x_test,y_test, key = \"rand_init_classifier\")\n",
    "    histories[\"rand_init_classifier\"].append(history)\n",
    "    results[\"rand_init_classifier\"].append(result)\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "supervised_and_unsupervised_class.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
